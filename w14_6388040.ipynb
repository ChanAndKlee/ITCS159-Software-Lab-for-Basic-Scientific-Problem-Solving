{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6388040 Ariya Phengphon (Section 2)\n",
    "### Lab 13 : Introduction to text processing using NLTK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ------ **Milestone 1 completed** ------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "- Process of breaking down a text paragraph into smaller chunks such as words or sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Tokenization\n",
    "breaks text paragraph into sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Dogs ,Canis lupus familiaris, are domesticated mammals,\\nnot natural wild animals.', 'They were originally bred from\\nwolves.', 'They have been bred by humans for a long time, and\\nwere the first animals ever to be domesticated.', 'Today, some dogs are used as pets, others are used to help\\nhumans do their work.', 'They are a popular pet because they\\nare usually playful, friendly, loyal and listen to humans.', 'Thirty million dogs in the United States are registered as\\npets.', 'Dogs eat both meat and vegetables, often mixed\\ntogether and sold in stores as dog food.', 'Dogs often have\\njobs, including as police dogs, army dogs, assistance dogs,\\nfire dogs, messenger dogs, hunting dogs, herding dogs, or\\nrescue dogs.', 'They are sometimes called \"canines\" from the Latin word for dog\\n- canis.', 'Sometimes people also use \"dog\" to describe other\\ncanids, such as wolves.', 'A baby dog is called a pup or puppy.', 'A dog is called a puppy until it is about one year old.', 'Dogs are sometimes referred to as \"man’s best friend\" because\\nthey are kept as domestic pets and are usually loyal and\\nlike being around humans.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "text=\"\"\"Dogs ,Canis lupus familiaris, are domesticated mammals,\n",
    "not natural wild animals. They were originally bred from\n",
    "wolves. They have been bred by humans for a long time, and\n",
    "were the first animals ever to be domesticated.\n",
    "Today, some dogs are used as pets, others are used to help\n",
    "humans do their work. They are a popular pet because they\n",
    "are usually playful, friendly, loyal and listen to humans.\n",
    "Thirty million dogs in the United States are registered as\n",
    "pets. Dogs eat both meat and vegetables, often mixed\n",
    "together and sold in stores as dog food. Dogs often have\n",
    "jobs, including as police dogs, army dogs, assistance dogs,\n",
    "fire dogs, messenger dogs, hunting dogs, herding dogs, or\n",
    "rescue dogs.\n",
    "They are sometimes called \"canines\" from the Latin word for dog\n",
    "- canis. Sometimes people also use \"dog\" to describe other\n",
    "canids, such as wolves. A baby dog is called a pup or puppy.\n",
    "A dog is called a puppy until it is about one year old.\n",
    "Dogs are sometimes referred to as \"man’s best friend\" because\n",
    "they are kept as domestic pets and are usually loyal and\n",
    "like being around humans.\"\"\"\n",
    "tokenized_text = sent_tokenize(text)\n",
    "print(tokenized_text)\n",
    "\n",
    "# How many sentences in the paragraph?\n",
    "# ANS 1st paragraph = 3 sentences\n",
    "#     2nd paragraph = 4 sentences\n",
    "#     3rd paragraph = 4 sentences\n",
    "#     4th paragraph = 1 sentences\n",
    "# What is the third sentences in the paragraph?\n",
    "# ANS They are sometimes called \"canines\" ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Tokenization\n",
    "breaks text paragraph into words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Dogs', ',', 'Canis', 'lupus', 'familiaris', ',', 'are', 'domesticated', 'mammals', ',', 'not', 'natural', 'wild', 'animals', '.', 'They', 'were', 'originally', 'bred', 'from', 'wolves', '.', 'They', 'have', 'been', 'bred', 'by', 'humans', 'for', 'a', 'long', 'time', ',', 'and', 'were', 'the', 'first', 'animals', 'ever', 'to', 'be', 'domesticated', '.', 'Today', ',', 'some', 'dogs', 'are', 'used', 'as', 'pets', ',', 'others', 'are', 'used', 'to', 'help', 'humans', 'do', 'their', 'work', '.', 'They', 'are', 'a', 'popular', 'pet', 'because', 'they', 'are', 'usually', 'playful', ',', 'friendly', ',', 'loyal', 'and', 'listen', 'to', 'humans', '.', 'Thirty', 'million', 'dogs', 'in', 'the', 'United', 'States', 'are', 'registered', 'as', 'pets', '.', 'Dogs', 'eat', 'both', 'meat', 'and', 'vegetables', ',', 'often', 'mixed', 'together', 'and', 'sold', 'in', 'stores', 'as', 'dog', 'food', '.', 'Dogs', 'often', 'have', 'jobs', ',', 'including', 'as', 'police', 'dogs', ',', 'army', 'dogs', ',', 'assistance', 'dogs', ',', 'fire', 'dogs', ',', 'messenger', 'dogs', ',', 'hunting', 'dogs', ',', 'herding', 'dogs', ',', 'or', 'rescue', 'dogs', '.', 'They', 'are', 'sometimes', 'called', '``', 'canines', \"''\", 'from', 'the', 'Latin', 'word', 'for', 'dog', '-', 'canis', '.', 'Sometimes', 'people', 'also', 'use', '``', 'dog', \"''\", 'to', 'describe', 'other', 'canids', ',', 'such', 'as', 'wolves', '.', 'A', 'baby', 'dog', 'is', 'called', 'a', 'pup', 'or', 'puppy', '.', 'A', 'dog', 'is', 'called', 'a', 'puppy', 'until', 'it', 'is', 'about', 'one', 'year', 'old', '.', 'Dogs', 'are', 'sometimes', 'referred', 'to', 'as', '``', 'man', '’', 's', 'best', 'friend', \"''\", 'because', 'they', 'are', 'kept', 'as', 'domestic', 'pets', 'and', 'are', 'usually', 'loyal', 'and', 'like', 'being', 'around', 'humans', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "tokenized_word = word_tokenize(text)\n",
    "print(tokenized_word)\n",
    "\n",
    "# How many words in the paragraph?\n",
    "# ANS 229 (count from https://wordcounter.net/).\n",
    "# How many words in the first sentence?\n",
    "# ANS 40 words.\n",
    "# How many words in the last sentence?\n",
    "# ANS 30 words.\n",
    "# Do you find repeat words?\n",
    "# yes ex Dogs, animals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 120 samples and 229 outcomes>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FreqDist({',': 18, '.': 13, 'are': 10, 'dogs': 10, 'as': 7, 'and': 6, 'to': 5, 'dog': 5, 'Dogs': 4, 'They': 4, ...})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.probability import FreqDist\n",
    "fdist = FreqDist(tokenized_word)\n",
    "print(fdist)\n",
    "\n",
    "# What is the output from print(fdist)?\n",
    "# ANS print the frequency of words within the text and all wordcounts in the text.\n",
    "\n",
    "fdist # print the words that frequency used (first 10 ranking DESC) in dictionary formating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 18),\n",
       " ('.', 13),\n",
       " ('are', 10),\n",
       " ('dogs', 10),\n",
       " ('as', 7),\n",
       " ('and', 6),\n",
       " ('to', 5),\n",
       " ('dog', 5),\n",
       " ('Dogs', 4),\n",
       " ('They', 4)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist.most_common(10) # print the same as above but in the list and can specify how much"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide a set of common stopwords\n",
    "my_stopwords = [\"is\", \"a\", \"this\", \",\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'y', 'me', 'not', 'are', 'all', 'too', 'mightn', 'before', 'ma', 'to', 'few', 'being', 'their', 'been', \"hadn't\", 'hasn', \"shan't\", \"aren't\", 'don', 'an', 'does', 'couldn', 'himself', 'myself', 'if', 'ain', 'once', 'own', \"should've\", \"you're\", 'she', 'other', 'whom', 'than', \"you've\", \"needn't\", \"couldn't\", 'a', 'these', 'my', 'of', \"wasn't\", 'has', 's', 'in', 'was', 'did', 'be', \"mustn't\", 'they', 'wouldn', \"wouldn't\", 'i', 'further', 'some', \"weren't\", 've', 're', 'doesn', 'any', 'so', 'shan', 'will', 'against', 'yours', 'by', 'shouldn', \"that'll\", 'theirs', 'over', 'then', 'out', 'we', 'is', 'how', 'ours', 'needn', 'same', \"shouldn't\", 'am', 'such', 'now', 'under', 'her', 'very', 'wasn', 'didn', \"hasn't\", 'nor', 'weren', 'during', 'the', 'from', 'both', 'while', \"doesn't\", \"didn't\", 'themselves', 'on', 'no', \"don't\", 'yourselves', 'it', 'between', 'above', 'when', 'itself', 'each', 'won', 'where', 'most', 'its', 'through', \"it's\", 'but', 'after', 'why', 'should', 'here', 'can', 'd', \"haven't\", 'yourself', 'doing', 'ourselves', 'having', 'what', 'off', 'or', 'again', 'only', \"she's\", 'aren', \"isn't\", 'isn', 'him', 'he', 'hadn', 'hers', 'into', 'more', 'm', 't', 'you', 'your', 'haven', 'do', 'them', 'were', 'for', 'below', 'as', 'this', 'up', \"won't\", 'until', 'and', 'had', 'because', 'those', 'mustn', 'there', \"you'd\", 'll', \"mightn't\", 'o', 'just', 'which', 'herself', 'his', 'who', 'with', 'have', 'at', \"you'll\", 'that', 'down', 'about', 'our'}\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "# stop_words by default NLTK\n",
    "nltk_stop_words = set(stopwords.words(\"english\")) # specify language\n",
    "print(nltk_stop_words)\n",
    "\n",
    "# What are those stopwords provided by NLTK?\n",
    "# ANS By default, NLTK (Natural Language Toolkit) includes a list of 40 stop words,\n",
    "# including: “a”, “an”, “the”, “of”, “in”, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any piece of text which is not relevant to the context of the data and the\n",
    "end-output can be specified as the noise.   (commonly used words of a language – is, am, the, of, in etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Stopwords\n",
    "use the stopwords that you prepared to remove noise\n",
    "from our text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Sentence: ['Dogs', ',', 'Canis', 'lupus', 'familiaris', ',', 'are', 'domesticated', 'mammals', ',', 'not', 'natural', 'wild', 'animals', '.', 'They', 'were', 'originally', 'bred', 'from', 'wolves', '.', 'They', 'have', 'been', 'bred', 'by', 'humans', 'for', 'a', 'long', 'time', ',', 'and', 'were', 'the', 'first', 'animals', 'ever', 'to', 'be', 'domesticated', '.', 'Today', ',', 'some', 'dogs', 'are', 'used', 'as', 'pets', ',', 'others', 'are', 'used', 'to', 'help', 'humans', 'do', 'their', 'work', '.', 'They', 'are', 'a', 'popular', 'pet', 'because', 'they', 'are', 'usually', 'playful', ',', 'friendly', ',', 'loyal', 'and', 'listen', 'to', 'humans', '.', 'Thirty', 'million', 'dogs', 'in', 'the', 'United', 'States', 'are', 'registered', 'as', 'pets', '.', 'Dogs', 'eat', 'both', 'meat', 'and', 'vegetables', ',', 'often', 'mixed', 'together', 'and', 'sold', 'in', 'stores', 'as', 'dog', 'food', '.', 'Dogs', 'often', 'have', 'jobs', ',', 'including', 'as', 'police', 'dogs', ',', 'army', 'dogs', ',', 'assistance', 'dogs', ',', 'fire', 'dogs', ',', 'messenger', 'dogs', ',', 'hunting', 'dogs', ',', 'herding', 'dogs', ',', 'or', 'rescue', 'dogs', '.', 'They', 'are', 'sometimes', 'called', '``', 'canines', \"''\", 'from', 'the', 'Latin', 'word', 'for', 'dog', '-', 'canis', '.', 'Sometimes', 'people', 'also', 'use', '``', 'dog', \"''\", 'to', 'describe', 'other', 'canids', ',', 'such', 'as', 'wolves', '.', 'A', 'baby', 'dog', 'is', 'called', 'a', 'pup', 'or', 'puppy', '.', 'A', 'dog', 'is', 'called', 'a', 'puppy', 'until', 'it', 'is', 'about', 'one', 'year', 'old', '.', 'Dogs', 'are', 'sometimes', 'referred', 'to', 'as', '``', 'man', '’', 's', 'best', 'friend', \"''\", 'because', 'they', 'are', 'kept', 'as', 'domestic', 'pets', 'and', 'are', 'usually', 'loyal', 'and', 'like', 'being', 'around', 'humans', '.']\n",
      "\n",
      "\n",
      "Filterd Sentence: ['Dogs', 'Canis', 'lupus', 'familiaris', 'are', 'domesticated', 'mammals', 'not', 'natural', 'wild', 'animals', '.', 'They', 'were', 'originally', 'bred', 'from', 'wolves', '.', 'They', 'have', 'been', 'bred', 'by', 'humans', 'for', 'long', 'time', 'and', 'were', 'the', 'first', 'animals', 'ever', 'to', 'be', 'domesticated', '.', 'Today', 'some', 'dogs', 'are', 'used', 'as', 'pets', 'others', 'are', 'used', 'to', 'help', 'humans', 'do', 'their', 'work', '.', 'They', 'are', 'popular', 'pet', 'because', 'they', 'are', 'usually', 'playful', 'friendly', 'loyal', 'and', 'listen', 'to', 'humans', '.', 'Thirty', 'million', 'dogs', 'in', 'the', 'United', 'States', 'are', 'registered', 'as', 'pets', '.', 'Dogs', 'eat', 'both', 'meat', 'and', 'vegetables', 'often', 'mixed', 'together', 'and', 'sold', 'in', 'stores', 'as', 'dog', 'food', '.', 'Dogs', 'often', 'have', 'jobs', 'including', 'as', 'police', 'dogs', 'army', 'dogs', 'assistance', 'dogs', 'fire', 'dogs', 'messenger', 'dogs', 'hunting', 'dogs', 'herding', 'dogs', 'or', 'rescue', 'dogs', '.', 'They', 'are', 'sometimes', 'called', '``', 'canines', \"''\", 'from', 'the', 'Latin', 'word', 'for', 'dog', '-', 'canis', '.', 'Sometimes', 'people', 'also', 'use', '``', 'dog', \"''\", 'to', 'describe', 'other', 'canids', 'such', 'as', 'wolves', '.', 'A', 'baby', 'dog', 'called', 'pup', 'or', 'puppy', '.', 'A', 'dog', 'called', 'puppy', 'until', 'it', 'about', 'one', 'year', 'old', '.', 'Dogs', 'are', 'sometimes', 'referred', 'to', 'as', '``', 'man', '’', 's', 'best', 'friend', \"''\", 'because', 'they', 'are', 'kept', 'as', 'domestic', 'pets', 'and', 'are', 'usually', 'loyal', 'and', 'like', 'being', 'around', 'humans', '.']\n"
     ]
    }
   ],
   "source": [
    "filtered_words=[]\n",
    "for w in tokenized_word: # loop in all words\n",
    "    if w not in my_stopwords: # if all words (check each) not in list of YOUR stop words\n",
    "        filtered_words.append(w) # append the perfect there (surely no all stop_words)\n",
    "\n",
    "print(\"Tokenized Sentence:\",tokenized_word)\n",
    "print(\"\\n\")\n",
    "print(\"Filterd Sentence:\",filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Sentence: ['Dogs', ',', 'Canis', 'lupus', 'familiaris', ',', 'are', 'domesticated', 'mammals', ',', 'not', 'natural', 'wild', 'animals', '.', 'They', 'were', 'originally', 'bred', 'from', 'wolves', '.', 'They', 'have', 'been', 'bred', 'by', 'humans', 'for', 'a', 'long', 'time', ',', 'and', 'were', 'the', 'first', 'animals', 'ever', 'to', 'be', 'domesticated', '.', 'Today', ',', 'some', 'dogs', 'are', 'used', 'as', 'pets', ',', 'others', 'are', 'used', 'to', 'help', 'humans', 'do', 'their', 'work', '.', 'They', 'are', 'a', 'popular', 'pet', 'because', 'they', 'are', 'usually', 'playful', ',', 'friendly', ',', 'loyal', 'and', 'listen', 'to', 'humans', '.', 'Thirty', 'million', 'dogs', 'in', 'the', 'United', 'States', 'are', 'registered', 'as', 'pets', '.', 'Dogs', 'eat', 'both', 'meat', 'and', 'vegetables', ',', 'often', 'mixed', 'together', 'and', 'sold', 'in', 'stores', 'as', 'dog', 'food', '.', 'Dogs', 'often', 'have', 'jobs', ',', 'including', 'as', 'police', 'dogs', ',', 'army', 'dogs', ',', 'assistance', 'dogs', ',', 'fire', 'dogs', ',', 'messenger', 'dogs', ',', 'hunting', 'dogs', ',', 'herding', 'dogs', ',', 'or', 'rescue', 'dogs', '.', 'They', 'are', 'sometimes', 'called', '``', 'canines', \"''\", 'from', 'the', 'Latin', 'word', 'for', 'dog', '-', 'canis', '.', 'Sometimes', 'people', 'also', 'use', '``', 'dog', \"''\", 'to', 'describe', 'other', 'canids', ',', 'such', 'as', 'wolves', '.', 'A', 'baby', 'dog', 'is', 'called', 'a', 'pup', 'or', 'puppy', '.', 'A', 'dog', 'is', 'called', 'a', 'puppy', 'until', 'it', 'is', 'about', 'one', 'year', 'old', '.', 'Dogs', 'are', 'sometimes', 'referred', 'to', 'as', '``', 'man', '’', 's', 'best', 'friend', \"''\", 'because', 'they', 'are', 'kept', 'as', 'domestic', 'pets', 'and', 'are', 'usually', 'loyal', 'and', 'like', 'being', 'around', 'humans', '.']\n",
      "\n",
      "\n",
      "Filterd Sentence: ['Dogs', ',', 'Canis', 'lupus', 'familiaris', ',', 'domesticated', 'mammals', ',', 'natural', 'wild', 'animals', '.', 'They', 'originally', 'bred', 'wolves', '.', 'They', 'bred', 'humans', 'long', 'time', ',', 'first', 'animals', 'ever', 'domesticated', '.', 'Today', ',', 'dogs', 'used', 'pets', ',', 'others', 'used', 'help', 'humans', 'work', '.', 'They', 'popular', 'pet', 'usually', 'playful', ',', 'friendly', ',', 'loyal', 'listen', 'humans', '.', 'Thirty', 'million', 'dogs', 'United', 'States', 'registered', 'pets', '.', 'Dogs', 'eat', 'meat', 'vegetables', ',', 'often', 'mixed', 'together', 'sold', 'stores', 'dog', 'food', '.', 'Dogs', 'often', 'jobs', ',', 'including', 'police', 'dogs', ',', 'army', 'dogs', ',', 'assistance', 'dogs', ',', 'fire', 'dogs', ',', 'messenger', 'dogs', ',', 'hunting', 'dogs', ',', 'herding', 'dogs', ',', 'rescue', 'dogs', '.', 'They', 'sometimes', 'called', '``', 'canines', \"''\", 'Latin', 'word', 'dog', '-', 'canis', '.', 'Sometimes', 'people', 'also', 'use', '``', 'dog', \"''\", 'describe', 'canids', ',', 'wolves', '.', 'A', 'baby', 'dog', 'called', 'pup', 'puppy', '.', 'A', 'dog', 'called', 'puppy', 'one', 'year', 'old', '.', 'Dogs', 'sometimes', 'referred', '``', 'man', '’', 'best', 'friend', \"''\", 'kept', 'domestic', 'pets', 'usually', 'loyal', 'like', 'around', 'humans', '.']\n"
     ]
    }
   ],
   "source": [
    "# Can you apply the stopwords provided by NLTK (nltk stop words) to your text?\n",
    "filtered_words=[]\n",
    "for w in tokenized_word: # loop in all words\n",
    "    if w not in nltk_stop_words: # if all words (check each) not in list of YOUR stop words\n",
    "        filtered_words.append(w) # append the perfect there (surely no all stop_words)\n",
    "\n",
    "print(\"Tokenized Sentence:\",tokenized_word)\n",
    "print(\"\\n\")\n",
    "print(\"Filterd Sentence:\",filtered_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ------ **Milestone 2 completed** ------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lexicon Normalization\n",
    "Lexicon normalization considers another type of noise in the text.  \n",
    "The most common lexicon normalization practices are  \n",
    "• **Stemming** => process of linguistic normalization, reduces words to their word root word or **chops off the derivational affixes**  (“ing”, “ly”, “es”, “s” etc)  For example, connection, connected, connecting word reduce to a common word “connect”.  \n",
    "• **Lemmatization** => is an organized and step by step procedure of obtaining the root form of the word, it makes use of vocabulary (dictionary importance of words) and morphological analysis (word structure and grammar relations)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connect\n",
      "deriv\n",
      "multipli\n",
      "Filtered Words: ['Dogs', ',', 'Canis', 'lupus', 'familiaris', ',', 'domesticated', 'mammals', ',', 'natural', 'wild', 'animals', '.', 'They', 'originally', 'bred', 'wolves', '.', 'They', 'bred', 'humans', 'long', 'time', ',', 'first', 'animals', 'ever', 'domesticated', '.', 'Today', ',', 'dogs', 'used', 'pets', ',', 'others', 'used', 'help', 'humans', 'work', '.', 'They', 'popular', 'pet', 'usually', 'playful', ',', 'friendly', ',', 'loyal', 'listen', 'humans', '.', 'Thirty', 'million', 'dogs', 'United', 'States', 'registered', 'pets', '.', 'Dogs', 'eat', 'meat', 'vegetables', ',', 'often', 'mixed', 'together', 'sold', 'stores', 'dog', 'food', '.', 'Dogs', 'often', 'jobs', ',', 'including', 'police', 'dogs', ',', 'army', 'dogs', ',', 'assistance', 'dogs', ',', 'fire', 'dogs', ',', 'messenger', 'dogs', ',', 'hunting', 'dogs', ',', 'herding', 'dogs', ',', 'rescue', 'dogs', '.', 'They', 'sometimes', 'called', '``', 'canines', \"''\", 'Latin', 'word', 'dog', '-', 'canis', '.', 'Sometimes', 'people', 'also', 'use', '``', 'dog', \"''\", 'describe', 'canids', ',', 'wolves', '.', 'A', 'baby', 'dog', 'called', 'pup', 'puppy', '.', 'A', 'dog', 'called', 'puppy', 'one', 'year', 'old', '.', 'Dogs', 'sometimes', 'referred', '``', 'man', '’', 'best', 'friend', \"''\", 'kept', 'domestic', 'pets', 'usually', 'loyal', 'like', 'around', 'humans', '.']\n",
      "\n",
      "\n",
      "Stemmed Words: ['dog', ',', 'cani', 'lupu', 'familiari', ',', 'domest', 'mammal', ',', 'natur', 'wild', 'anim', '.', 'they', 'origin', 'bred', 'wolv', '.', 'they', 'bred', 'human', 'long', 'time', ',', 'first', 'anim', 'ever', 'domest', '.', 'today', ',', 'dog', 'use', 'pet', ',', 'other', 'use', 'help', 'human', 'work', '.', 'they', 'popular', 'pet', 'usual', 'play', ',', 'friendli', ',', 'loyal', 'listen', 'human', '.', 'thirti', 'million', 'dog', 'unit', 'state', 'regist', 'pet', '.', 'dog', 'eat', 'meat', 'veget', ',', 'often', 'mix', 'togeth', 'sold', 'store', 'dog', 'food', '.', 'dog', 'often', 'job', ',', 'includ', 'polic', 'dog', ',', 'armi', 'dog', ',', 'assist', 'dog', ',', 'fire', 'dog', ',', 'messeng', 'dog', ',', 'hunt', 'dog', ',', 'herd', 'dog', ',', 'rescu', 'dog', '.', 'they', 'sometim', 'call', '``', 'canin', \"''\", 'latin', 'word', 'dog', '-', 'cani', '.', 'sometim', 'peopl', 'also', 'use', '``', 'dog', \"''\", 'describ', 'canid', ',', 'wolv', '.', 'a', 'babi', 'dog', 'call', 'pup', 'puppi', '.', 'a', 'dog', 'call', 'puppi', 'one', 'year', 'old', '.', 'dog', 'sometim', 'refer', '``', 'man', '’', 'best', 'friend', \"''\", 'kept', 'domest', 'pet', 'usual', 'loyal', 'like', 'around', 'human', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stem = PorterStemmer()\n",
    "word = \"connection\"\n",
    "word2 = \"derivational\"\n",
    "word3 = \"multiplying\"\n",
    "\n",
    "print(stem.stem(word))\n",
    "print(stem.stem(word2))\n",
    "print(stem.stem(word3))\n",
    "\n",
    "# What is the output? Can you try some other words such as derivational, multiplying?\n",
    "# ANS The output is a root of this words with chopping off the derivational affixes.\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "stem = PorterStemmer()\n",
    "stemmed_words = []\n",
    "\n",
    "for w in filtered_words: # filtered_words => words that already cut the stop words\n",
    "    stemmed_words.append(stem.stem(w)) # append word the already converted to root words inside the list\n",
    "\n",
    "print(\"Filtered Words:\",filtered_words)\n",
    "print(\"\\n\")\n",
    "print(\"Stemmed Words:\",stemmed_words)\n",
    "\n",
    "# What is the output?\n",
    "# ANS  filtered_words is the words that already cut the stop words\n",
    "# stemmed_words is the words that already converted to root words inside the list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connect\n",
      "connecting\n",
      "connecting\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lem = WordNetLemmatizer()\n",
    "word = \"connecting\"\n",
    "print(lem.lemmatize(word, pos = \"v\")) # verb\n",
    "print(lem.lemmatize(word, pos = \"a\")) # adjective\n",
    "print(lem.lemmatize(word, pos = \"n\")) # noun\n",
    "\n",
    "# One major difference with stemming is that lemmatize takes a part of speech parameter,\n",
    "# “pos” If not supplied, the default is “noun.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fly\n",
      "flying\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lem = WordNetLemmatizer()\n",
    "word = \"flying\"\n",
    "print(lem.lemmatize(word, pos=\"v\"))\n",
    "print(lem.lemmatize(word, pos=\"n\"))\n",
    "\n",
    "# What is the different between using v and n?\n",
    "# ANS verb and noun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS Tagging\n",
    "The primary target of Part-of-Speech(POS) tagging is to identify the grammatical group of a given word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'am', 'studying', 'at', 'ICT']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('I', 'PRP'),\n",
       " ('am', 'VBP'),\n",
       " ('studying', 'VBG'),\n",
       " ('at', 'IN'),\n",
       " ('ICT', 'NNP')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = \"I am studying at ICT\"\n",
    "tokens = nltk.word_tokenize(sent)\n",
    "print(tokens) # chop into each word first\n",
    "nltk.pos_tag(tokens) # interpret each of them as POS\n",
    "\n",
    "# Can you try to interpret the result?\n",
    "# ANS The result is showing the grammatical group (part-of-speech) of each word in the sentence\n",
    "\n",
    "# PRP - Personal Pronoun (I, he, she)\n",
    "# VBP - Verb (Present, non-3d)\n",
    "# VBG - Verb (Gerund, Present Participle V-ing)\n",
    "# IN  - Preposition/Subordinating Conjunction (which, in order that, when, ...)\n",
    "# NNP - Proper Noun (Singular)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ------ **Milestone 3 completed** ------"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "23300995598eec4bcf6bd89cf02d1c3675e8b2616661418dbbf5580aa901878d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
